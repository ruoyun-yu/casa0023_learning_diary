---
title: "week7"
format: html
editor: visual
number-sections: true
---

# 7.1 Summary

This week's lecture focused on classification

**1. Classification process**

i)  Confirm training data and forecast data
ii) Establish a classification model
iii) Generate classification results and evaluate accuracy\

**2. Classification type**

i)  Supervised classification: Manually provide training samples, such as decision trees and support vector machines (SVM).
ii) Unsupervised classification: there is no manual annotation, only the number of categories is set, and the algorithm automatically clustering data, such as ISODATA method
iii) Traditional classifiers & Machine learning classifiers:

-   Traditional classifiers (not model-based) : Maximum Likelihood, Parallelpiped, ISODATA, etc., mainly divide data based on feature space.
-   Machine learning classifiers (model-based) : decision trees, SVMS, etc., use training data to build more complex classification models.

**3. Classification Tree& Regression Tree**

i)  Classification Tree It is mainly used for the prediction of discrete or classified data with the Impurity impurity impurity selected as the root node.
ii) Regression Tree It is mainly used for prediction of continuous data and is used when linear regression does not fit the data well. The partition point with the smallest residual sum of squares (SSR) was selected as the split node
iii) Methods to prevent overfitting

-   Sets the maximum tree depth

-   Sets the minimum number of leaf nodes

-   Weakest Link Pruning

-   Cross-Validation e.g. k-fold cross-validation

-   Random Forest

    *Spatial overfitting: If the training set is geographically close to the test set, it may lead to overfitting and affect the model generalization ability.*

    -   *Sets a minimum distance threshold to ensure that there is space between the training and validation data.*

    -   *Cluster the training data to ensure that there is sufficient diversity among different datasets*

    -   *Accuracy does not equal predictive power: Models without spatial autocorrelation are usually more accurate than models with spatial autocorrelation, but this does not mean that they are more predictive.*

iv) Evaluation Decision trees are highly interpretable, while deep learning is highly accurate but highly black box.

**4. Support Vector Machine (SVM)**

-   Essentially similar to regression, finding the optimal Hyperplane divides the data. The C parameter controls the decision boundary width of the hyperplane (allowing certain misclassification).
-   The Gamma parameter controls the range of influence, with high values considered local and low values considered global. Kernel Trick allows nonlinear data to be mapped so that it is separable in high dimensional space.
-   Automatically tune C and Gamma parameters via Grid Search.
-   SVM ensures optimal separation by maximizing the distance from the support vector of the two classes to the hyperplane.

# 7.2 Application

Classification can refer to crop type classification or urban land use classification. In practical applications, supervised classification can be implemented using various algorithms. A review of the literature reveals that different data and implementation processes are adopted depending on the objective. Hyperspectral imagery can be utilized, and preprocessing before image classification can improve classification accuracy. If low cost and speed are prioritized, noise-resistant algorithms can be used, with OSM as the training data, eliminating the need for manual selection of training data.

+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Article Title              | Land Use Classification of Hyperspectral Data by Spectral Angle Mapper and Support Vector Machine in Humid Tropical Region of India                               | Integrating OpenStreetMap Crowdsourced Data and Landsat Time-Series Imagery for Rapid Land Use/Land Cover (LULC) Mapping: Case Study of the Laguna de Bay Area of the Philippines                                                          |
+============================+===================================================================================================================================================================+============================================================================================================================================================================================================================================+
| Study Area Characteristics | Cloudy and foggy, diverse crop types                                                                                                                              | Cloudy and foggy, rapid land use changes                                                                                                                                                                                                   |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Content           | Using SAM and SVM with hyperspectral imagery to classify nine types of crop land use in the study area and comparing the classification accuracy of both methods. | Selecting NB, C4.5, and RF (+SMOTE) as noise-resistant classification algorithms with Landsat multispectral imagery. Automatically extracting training samples from OSM and conducting land use classification with preprocessed data.     |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Remote Sensing Data        | Hyperspectral data from EO-1 Hyperion                                                                                                                             | Multi-temporal Landsat 8 + OSM crowdsourced data                                                                                                                                                                                           |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Data Preprocessing         | 1.  **Sensor calibration**: Removing overlapping bands.                                                                                                           | Landsat data is directly used without preprocessing.                                                                                                                                                                                       |
|                            | 2.  **Extracting radiance values**Â from the imagery.                                                                                                              |                                                                                                                                                                                                                                            |
|                            | 3.  **Atmospheric correction**: Using the FLAASH module to eliminate low reflectance bands.                                                                       |                                                                                                                                                                                                                                            |
|                            | 4.  **Geometric correction**: Using IRS-P6 LISS III imagery as a reference.                                                                                       |                                                                                                                                                                                                                                            |
|                            | 5.  **Dimensionality reduction**: Applying Principal Component Analysis (PCA) to optimize computational complexity.                                               |                                                                                                                                                                                                                                            |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Image Classification       | 1.  **Geometric-distance-based classification**: Spectral Angle Mapper (SAM).                                                                                     | 1.  **Converting categorical data**: OSM-LU and OSM-N categories are converted into four, five, and six land cover classes.                                                                                                                |
|                            | 2.  **Supervised classification**: Support Vector Machine (SVM).                                                                                                  |                                                                                                                                                                                                                                            |
|                            |                                                                                                                                                                   | 2.  **Extracting training pixels**: OSM polygons are randomly split 50/50 to create independent training and validation datasets. Random points are generated within each training polygon to serve as training pixels for classification. |
|                            |                                                                                                                                                                   |                                                                                                                                                                                                                                            |
|                            |                                                                                                                                                                   | 3.  **Supervised image classification**:                                                                                                                                                                                                   |
|                            |                                                                                                                                                                   |                                                                                                                                                                                                                                            |
|                            |                                                                                                                                                                   |     NB, C4.5, RF (+SMOTE).                                                                                                                                                                                                                 |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Accuracy Evaluation        | Based on ground truth data, calculatingÂ overall accuracy (OA)Â andÂ Kappa coefficient.                                                                              | Using high-resolution Google Earth imagery to determine the actual land use/land cover class for each point. CalculatingÂ overall accuracy (OA), producerâs accuracy (PA), and userâs accuracy (UA).                                        |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+
| Research Findings          | SVM outperforms SAM.                                                                                                                                              | RF (+SMOTE) performs best in the four-class classification.                                                                                                                                                                                |
|                            |                                                                                                                                                                   |                                                                                                                                                                                                                                            |
|                            |                                                                                                                                                                   | -   RF is more effective in classifying "impervious surfaces" and "farmland."                                                                                                                                                              |
|                            |                                                                                                                                                                   |                                                                                                                                                                                                                                            |
|                            |                                                                                                                                                                   | -   NB performs better in classifying "orchards" and "forests."                                                                                                                                                                            |
|                            |                                                                                                                                                                   |                                                                                                                                                                                                                                            |
|                            |                                                                                                                                                                   | -   The SMOTE technique significantly improves classification accuracy, especially in decision-tree-based algorithms.                                                                                                                      |
+----------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+

1.  **SAM vs SVM**

    SAM classifies by calculating the Angle between the spectral vector of each pixel in the image and the spectral vector of a spectral library (or training sample) of a known class. The smaller the spectral Angle, the more similar the pixel is to the class. SVM separates different categories of data by finding an optimal hyperplane in the feature space. The classification effect of SVM is better than that of SAM mainly in the following aspects: Adaptability: SVM can handle complex, non-linear data, map the data to high-dimensional Spaces through kernel functions, and handle more complex boundaries. SAM is suitable for data with obvious spectral characteristics and linear separability, and the effect is simple and the noise is small. Noise robustness: SVM deals with noise through regularization and kernel functions, which can reduce errors. SAM is sensitive to noise, especially when the data quality is poor. Classification accuracy: SVM can find more complex decision boundaries and is generally more accurate in remote sensing classification. SAM is only suitable for data with large spectral differences.

2.  **How does the synthetic Minority oversampling technique work when dealing with training data imbalances?**

    SMOTE balances the training data set by inserting synthetic samples between a few class samples. The specific steps are as follows:

<!-- -->

I)  Calculate the distance between samples: For each minority sample, calculate the Euclidean distance between it and other minority samples.
II) Selection of interpolation points: The interpolation points are selected according to the distance, usually the nearest neighbor sample whose distance is less than a certain threshold.
III) Generation of new samples: at the selected interpolation points, a new minority class sample is generated by linear interpolation or other methods.

<!-- -->

3.  **Sources of data noise**

    Landsat data is affected by clouds and has attribute noise The error of OSM data when combining categories and the inaccurate boundary of original OSM data when delimited in the field lead to class noise

# 7.3 Reflection
