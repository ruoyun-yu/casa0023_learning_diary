[
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "week7",
    "section": "",
    "text": "1 7.1 Summary\nThis week’s lecture focused on classification\n1. Classification process\n\nConfirm training data and forecast data\nEstablish a classification model\nGenerate classification results and evaluate accuracy\n\n\n2. Classification type\n\nSupervised classification: Manually provide training samples, such as decision trees and support vector machines (SVM).\nUnsupervised classification: there is no manual annotation, only the number of categories is set, and the algorithm automatically clustering data, such as ISODATA method\nTraditional classifiers & Machine learning classifiers:\n\n\nTraditional classifiers (not model-based) : Maximum Likelihood, Parallelpiped, ISODATA, etc., mainly divide data based on feature space.\nMachine learning classifiers (model-based) : decision trees, SVMS, etc., use training data to build more complex classification models.\n\n3. Classification Tree& Regression Tree\n\nClassification Tree It is mainly used for the prediction of discrete or classified data with the Impurity impurity impurity selected as the root node.\nRegression Tree It is mainly used for prediction of continuous data and is used when linear regression does not fit the data well. The partition point with the smallest residual sum of squares (SSR) was selected as the split node\nMethods to prevent overfitting\n\n\nSets the maximum tree depth\nSets the minimum number of leaf nodes\nWeakest Link Pruning\nCross-Validation e.g. k-fold cross-validation\nRandom Forest\nSpatial overfitting: If the training set is geographically close to the test set, it may lead to overfitting and affect the model generalization ability.\n\nSets a minimum distance threshold to ensure that there is space between the training and validation data.\nCluster the training data to ensure that there is sufficient diversity among different datasets\nAccuracy does not equal predictive power: Models without spatial autocorrelation are usually more accurate than models with spatial autocorrelation, but this does not mean that they are more predictive.\n\n\n\nEvaluation Decision trees are highly interpretable, while deep learning is highly accurate but highly black box.\n\n4. Support Vector Machine (SVM)\n\nEssentially similar to regression, finding the optimal Hyperplane divides the data. The C parameter controls the decision boundary width of the hyperplane (allowing certain misclassification).\nThe Gamma parameter controls the range of influence, with high values considered local and low values considered global. Kernel Trick allows nonlinear data to be mapped so that it is separable in high dimensional space.\nAutomatically tune C and Gamma parameters via Grid Search.\nSVM ensures optimal separation by maximizing the distance from the support vector of the two classes to the hyperplane.\n\n\n\n2 7.2 Application\nClassification can refer to crop type classification or urban land use classification. In practical applications, supervised classification can be implemented using various algorithms. A review of the literature reveals that different data and implementation processes are adopted depending on the objective. Hyperspectral imagery can be utilized, and preprocessing before image classification can improve classification accuracy. If low cost and speed are prioritized, noise-resistant algorithms can be used, with OSM as the training data, eliminating the need for manual selection of training data.\n\n\n\n\n\n\n\n\nArticle Title\nLand Use Classification of Hyperspectral Data by Spectral Angle Mapper and Support Vector Machine in Humid Tropical Region of India\nIntegrating OpenStreetMap Crowdsourced Data and Landsat Time-Series Imagery for Rapid Land Use/Land Cover (LULC) Mapping: Case Study of the Laguna de Bay Area of the Philippines\n\n\n\n\nStudy Area Characteristics\nCloudy and foggy, diverse crop types\nCloudy and foggy, rapid land use changes\n\n\nResearch Content\nUsing SAM and SVM with hyperspectral imagery to classify nine types of crop land use in the study area and comparing the classification accuracy of both methods.\nSelecting NB, C4.5, and RF (+SMOTE) as noise-resistant classification algorithms with Landsat multispectral imagery. Automatically extracting training samples from OSM and conducting land use classification with preprocessed data.\n\n\nRemote Sensing Data\nHyperspectral data from EO-1 Hyperion\nMulti-temporal Landsat 8 + OSM crowdsourced data\n\n\nData Preprocessing\n\nSensor calibration: Removing overlapping bands.\nExtracting radiance values from the imagery.\nAtmospheric correction: Using the FLAASH module to eliminate low reflectance bands.\nGeometric correction: Using IRS-P6 LISS III imagery as a reference.\nDimensionality reduction: Applying Principal Component Analysis (PCA) to optimize computational complexity.\n\nLandsat data is directly used without preprocessing.\n\n\nImage Classification\n\nGeometric-distance-based classification: Spectral Angle Mapper (SAM).\nSupervised classification: Support Vector Machine (SVM).\n\n\nConverting categorical data: OSM-LU and OSM-N categories are converted into four, five, and six land cover classes.\nExtracting training pixels: OSM polygons are randomly split 50/50 to create independent training and validation datasets. Random points are generated within each training polygon to serve as training pixels for classification.\nSupervised image classification:\nNB, C4.5, RF (+SMOTE).\n\n\n\nAccuracy Evaluation\nBased on ground truth data, calculating overall accuracy (OA) and Kappa coefficient.\nUsing high-resolution Google Earth imagery to determine the actual land use/land cover class for each point. Calculating overall accuracy (OA), producer’s accuracy (PA), and user’s accuracy (UA).\n\n\nResearch Findings\nSVM outperforms SAM.\nRF (+SMOTE) performs best in the four-class classification.\n\nRF is more effective in classifying “impervious surfaces” and “farmland.”\nNB performs better in classifying “orchards” and “forests.”\nThe SMOTE technique significantly improves classification accuracy, especially in decision-tree-based algorithms.\n\n\n\n\n\nSAM vs SVM\nSAM classifies by calculating the Angle between the spectral vector of each pixel in the image and the spectral vector of a spectral library (or training sample) of a known class. The smaller the spectral Angle, the more similar the pixel is to the class. SVM separates different categories of data by finding an optimal hyperplane in the feature space. The classification effect of SVM is better than that of SAM mainly in the following aspects: Adaptability: SVM can handle complex, non-linear data, map the data to high-dimensional Spaces through kernel functions, and handle more complex boundaries. SAM is suitable for data with obvious spectral characteristics and linear separability, and the effect is simple and the noise is small. Noise robustness: SVM deals with noise through regularization and kernel functions, which can reduce errors. SAM is sensitive to noise, especially when the data quality is poor. Classification accuracy: SVM can find more complex decision boundaries and is generally more accurate in remote sensing classification. SAM is only suitable for data with large spectral differences.\nHow does the synthetic Minority oversampling technique work when dealing with training data imbalances?\nSMOTE balances the training data set by inserting synthetic samples between a few class samples. The specific steps are as follows:\n\n\n\nCalculate the distance between samples: For each minority sample, calculate the Euclidean distance between it and other minority samples.\nSelection of interpolation points: The interpolation points are selected according to the distance, usually the nearest neighbor sample whose distance is less than a certain threshold.\nGeneration of new samples: at the selected interpolation points, a new minority class sample is generated by linear interpolation or other methods.\n\n\n\nSources of data noise\nLandsat data is affected by clouds and has attribute noise The error of OSM data when combining categories and the inaccurate boundary of original OSM data when delimited in the field lead to class noise\n\n\n\n3 7.3 Reflection"
  },
  {
    "objectID": "week4.html",
    "href": "week4.html",
    "title": "week4",
    "section": "",
    "text": "London is a green city, with over 47% of its area classified as green or blue and more than 8 million trees. The total asset value of London’s public green spaces exceeds £91 billion, with an estimated annual value of £5 billion. Additionally, access to green spaces helps Londoners save approximately £950 million annually in health costs. Besides, parks and green spaces in England contribute £6.6 billion annually in benefits related to health, climate change, and the environment.\n\n\nHowever, due to population growth and land development, the extent of green spaces in both London and England has significantly declined over the past decade. A 2019 Committee on Climate Change report stated that the proportion of green space in England’s urban areas decreased from 63% in 2001 to 55% in 2018.\nUrban resilience refers to a city’s ability to withstand and recover from shocks and stresses, encompassing economic, social, environmental, and institutional resilience. 《World Cities Report 2022: Envisaging the Future of Cities》highlights that investing in green-blue infrastructure is one of the two key areas essential for enhancing environmental resilience. Blue-green infrastructure includes the ‘green’ and ‘blue’ features of our towns and cities that provide environmental benefits and contribute to our quality of life.\nIn recent years, London has increased its focus on urban resilience and green infrastructure, as reflected in various policies. The London Plan 2021, in Chapter 8 (Green Infrastructure), outlines specific requirements for green infrastructure development:\n-Policy G1 Green infrastructure\nLondon’s network of green and open spaces, and green features in the built environment, should be protected and enhanced. Development Plans and area-based strategies should identify key green infrastructure assets, along with their existing and potential functions.\n-Policy G7 Trees and woodlands\nLondon’s urban forest and woodlands should be protected and maintained, and new trees and woodlands should be planted in appropriate locations in order to increase the extent of London’s urban forest\nAlthough the London City Resilience Strategy 2020 does not set explicit targets for green-blue infrastructure, it emphasizes the importance of data in infrastructure planning and advocates for improving the resilience of London’s infrastructure systems while prioritizing investment through the use of data."
  },
  {
    "objectID": "week4.html#summary",
    "href": "week4.html#summary",
    "title": "week4",
    "section": "",
    "text": "London is a green city, with over 47% of its area classified as green or blue and more than 8 million trees. The total asset value of London’s public green spaces exceeds £91 billion, with an estimated annual value of £5 billion. Additionally, access to green spaces helps Londoners save approximately £950 million annually in health costs. Besides, parks and green spaces in England contribute £6.6 billion annually in benefits related to health, climate change, and the environment.\n\n\nHowever, due to population growth and land development, the extent of green spaces in both London and England has significantly declined over the past decade. A 2019 Committee on Climate Change report stated that the proportion of green space in England’s urban areas decreased from 63% in 2001 to 55% in 2018.\nUrban resilience refers to a city’s ability to withstand and recover from shocks and stresses, encompassing economic, social, environmental, and institutional resilience. 《World Cities Report 2022: Envisaging the Future of Cities》highlights that investing in green-blue infrastructure is one of the two key areas essential for enhancing environmental resilience. Blue-green infrastructure includes the ‘green’ and ‘blue’ features of our towns and cities that provide environmental benefits and contribute to our quality of life.\nIn recent years, London has increased its focus on urban resilience and green infrastructure, as reflected in various policies. The London Plan 2021, in Chapter 8 (Green Infrastructure), outlines specific requirements for green infrastructure development:\n-Policy G1 Green infrastructure\nLondon’s network of green and open spaces, and green features in the built environment, should be protected and enhanced. Development Plans and area-based strategies should identify key green infrastructure assets, along with their existing and potential functions.\n-Policy G7 Trees and woodlands\nLondon’s urban forest and woodlands should be protected and maintained, and new trees and woodlands should be planted in appropriate locations in order to increase the extent of London’s urban forest\nAlthough the London City Resilience Strategy 2020 does not set explicit targets for green-blue infrastructure, it emphasizes the importance of data in infrastructure planning and advocates for improving the resilience of London’s infrastructure systems while prioritizing investment through the use of data."
  },
  {
    "objectID": "week4.html#application",
    "href": "week4.html#application",
    "title": "week4",
    "section": "4.2 Application",
    "text": "4.2 Application\nRemote sensing imagery plays a crucial role in supporting urban green infrastructure planning and policy responses. For example, it can be used to quantify urban forest structure, providing governments with accurate data support. The study 《Quantifying urban forest structure with open-access remote sensing data sets》uses a random forest approach to train the model and apply it to urban forest structure assessment. It first calculates canopy cover, canopy height, and tree density using LiDAR data from the UK Environment Agency. Then, it incorporates Sentinel-2 satellite imagery, climate, and terrain data, which are preprocessed via Google Earth Engine. The random forest model predicts forest structure indicators and is applied at both 100m and 20m grid scales. Additionally, the study validates the model’s accuracy using iTree Eco data and explores its transferability across different urban environments.\n\nMoreover, remote sensing can identify potential areas for urban tree planting, assess the economic benefits of green infrastructure development, and provide data-driven support for optimizing urban green space layouts. The study《Efficient assessments of urban tree planting potential within or near the southern Piedmont region of the United States》employs supervised classification to analyze remote sensing imagery, categorizing land into four classes: water, developed land, open land, and forest. Using NAIP imagery as reference data, the study validates classification accuracy through random sampling. When evaluating suitable planting areas, it excludes obstacles such as buildings, roads, and water bodies, as well as small forest gaps. The proportion of plantable land within open spaces is calculated for each city. For other cities, the study applies the same classification method to identify open areas and estimates total tree planting potential by extrapolating from similar urban areas.\nThese studies demonstrate that remote sensing technology can provide efficient and accurate data support, enabling governments to develop more informed urban green space plans, optimize green infrastructure layouts, and assess their environmental and economic benefits."
  },
  {
    "objectID": "week4.html#reflection",
    "href": "week4.html#reflection",
    "title": "week4",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "casa0023_learning_diary",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "week2",
    "section": "",
    "text": "xaringanExtra::embed_xaringan(url = “https://raw.githubusercontent.com/ruoyun-yu/casa0023_learning_diary/main/week2_iceye.html”, ratio = “16:9”)"
  },
  {
    "objectID": "week2.html#section",
    "href": "week2.html#section",
    "title": "week2",
    "section": "",
    "text": "xaringanExtra::embed_xaringan(url = “https://raw.githubusercontent.com/ruoyun-yu/casa0023_learning_diary/main/week2_iceye.html”, ratio = “16:9”)"
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "week6",
    "section": "",
    "text": "6.1 Summary\nThis week’s lecture focused on Google earth engine\n\nImportant terms of GEE\n\n\nImage = Raster\nFeature = Vector\nImage Collection = a set of time series raster data\nFeature Collection= Multiple vector objects\n\n\nGEEoperation mode\nIt adopts the Client-Server architecture Parallelism is supported, with the for loop executing locally and the map() function processing in parallel Dynamic resolution adjustment, adjusting the resolution according to the zoom level\nPrecautions for data loading\n\n\n\nThe scale parameter determines the resolution of data export When the scale is lower than the original resolution of the image, the true resolution of the image is not increased, but the value of the original pixel. When the scale is higher than the original resolution (such as scale=50), multiple pixels are aggregated and the calculated value may change.\nGEE image loading and visualization need to specify the band and visualization parameters\nGEE will automatically convert the projection when processing remote sensing images, and most data will use EPSG:3857 (Web Mercator) by default.\nGEE main function\n\n\nee.Image: single raster image\nee.ImageCollection: Multiple raster images, such as data sets\nee.Geometry: points, polygons and other basic geometric shapes\nee.Feature: Geometric objects with attribute information, such as a country border data\nee.FeatureCollection: A collection of features\nee.Reducer: Aggregate data\nee.Join: Data merge, such as spatial join.\nee.Array: multidimensional data structure (similar to NumPy)\nee.Chart: An object that visualizes the analysis results\n\n\ntypical processes in GEE\n\n\n\nJoins\nZonal Statistics\nFiltering of images or specific values\nImage\nReduction\n\n\nReduce by Pixel\nReduce by Region Calculate statistics for a specific region\nReduce by Neighborhood\nThe pixel and the pixel around it are calculated to generate a new value\n\nset a window of pixels surrounding a central pixel (3*3, 5*5)\ncalculate like a filter or texture measure\npurpose: Edge Detection, Smoothing, Denoising and so on\n\n\n\n\n\n\n\n\n\n6.2 Application"
  }
]